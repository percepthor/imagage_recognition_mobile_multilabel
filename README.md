# Sistema de Reconocimiento de ImÃ¡genes Multi-Label para MÃ³viles

Sistema completo end-to-end para clasificaciÃ³n multi-label en dispositivos mÃ³viles, con entrenamiento optimizado usando teacher-student distillation y Quantization Aware Training (QAT).

## ğŸ¯ DescripciÃ³n

Este proyecto proporciona una soluciÃ³n completa para implementar clasificaciÃ³n multi-label en aplicaciones mÃ³viles (Android/iOS) con mÃ¡ximo rendimiento y mÃ­nimo tamaÃ±o de modelo.

### CaracterÃ­sticas Principales

- **Sistema de Entrenamiento Completo**: Pipeline automÃ¡tico con teacher-student distillation
- **OptimizaciÃ³n para MÃ³vil**: Modelos cuantizados INT8 con QAT
- **Plugin Flutter Nativo**: Inferencia en C para mÃ¡ximo rendimiento
- **Preprocesamiento Compatible**: Letterbox idÃ©ntico entre entrenamiento e inferencia
- **Anti-Overfitting**: Estrategias SOTA para datasets pequeÃ±os (~1000 imÃ¡genes)

## ğŸ“‚ Estructura del Proyecto

```
.
â”œâ”€â”€ trainer/                    # Sistema de entrenamiento
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ data/          # Procesamiento de datos
â”‚       â”‚   â”œâ”€â”€ models/        # Teacher & Student models
â”‚       â”‚   â”œâ”€â”€ train/         # LÃ³gica de entrenamiento
â”‚       â”‚   â”œâ”€â”€ eval/          # MÃ©tricas y evaluaciÃ³n
â”‚       â”‚   â””â”€â”€ export/        # ExportaciÃ³n TFLite
â”‚       â”œâ”€â”€ configs/           # Configuraciones
â”‚       â”œâ”€â”€ Dockerfile         # Container para entrenamiento
â”‚       â””â”€â”€ README.md          # DocumentaciÃ³n detallada
â”‚
â””â”€â”€ mobile/                     # Plugin Flutter
    â””â”€â”€ image_recognition/
        â”œâ”€â”€ src/               # Motor C de inferencia
        â”œâ”€â”€ ios/               # ImplementaciÃ³n iOS
        â”œâ”€â”€ android/           # ImplementaciÃ³n Android
        â””â”€â”€ example/           # App de ejemplo

```

## ğŸš€ Quick Start

### 1. Entrenar Modelo

```bash
cd trainer/training

# OpciÃ³n A: Con Docker
docker build -t multilabel-trainer .
docker run --rm \
  -v /path/to/dataset:/data/dataset \
  -v /path/to/output:/out \
  multilabel-trainer \
  python -m src.cli train \
    --data_dir /data/dataset \
    --out_dir /out/run_001 \
    --config /app/configs/default.yaml

# OpciÃ³n B: Sin Docker
pip install -r requirements.txt
python -m src.cli train \
  --data_dir /path/to/dataset \
  --out_dir /path/to/output \
  --config configs/default.yaml
```

### 2. Integrar en App MÃ³vil

```dart
import 'package:image_recognition/image_recognition.dart';

// Inicializar
final recognizer = ImageRecognition();
await recognizer.initialize(
  modelPath: 'assets/model_qat_int8.tflite',
  configPath: 'assets/inference_config.json',
);

// Reconocer imagen
final results = await recognizer.recognize(imageBytes);
for (var result in results) {
  print('${result.label}: ${result.confidence}');
}
```

## ğŸ“Š Arquitectura del Sistema

### Pipeline de Entrenamiento (9 Pasos AutomÃ¡ticos)

1. **Parse & Validate** - ValidaciÃ³n completa del dataset
2. **Build Datasets** - TF.data pipelines optimizados
3. **Train Teacher** - EfficientNet-B3 (2 fases)
4. **Train Student** - EfficientNet-Lite B1 con destilaciÃ³n
5. **Apply QAT** - Quantization Aware Training
6. **Optimize Thresholds** - Grid search en validation set
7. **Export TFLite** - Full-integer INT8 quantization
8. **Generate Metadata** - ConfiguraciÃ³n para inferencia
9. **Final Evaluation** - MÃ©tricas en test set

### Modelos

- **Teacher**: EfficientNet-B3 (300x300)
  - Mayor capacidad y precisiÃ³n
  - Solo para entrenamiento

- **Student**: EfficientNet-Lite B1 (240x240)
  - Optimizado para mÃ³vil
  - Cuantizado INT8
  - ~3-4 MB de tamaÃ±o

## ğŸ“ Teacher-Student Distillation

El student aprende tanto de:
- **Hard Targets**: Etiquetas ground truth
- **Soft Targets**: Predicciones del teacher (con temperatura)

Loss combinada:
```
L = Î± * L_hard + (1-Î±) * TÂ² * L_soft
```

Donde:
- Î± = 0.7 (peso para hard loss)
- T = 2.0 (temperatura)

## ğŸ“± Inferencia MÃ³vil

### Motor Nativo en C

```c
// Inicializar
ImageRecContext* ctx = image_rec_init(
    model_path,
    config_path
);

// Inferencia
ImageRecResult* results = NULL;
int num_results;
image_rec_recognize(
    ctx,
    image_data,
    width,
    height,
    channels,
    &results,
    &num_results
);
```

### CaracterÃ­sticas del Motor

- âœ… Letterbox automÃ¡tico (mantiene aspect ratio)
- âœ… NormalizaciÃ³n EfficientNet-Lite: `(x-127)/128`
- âœ… Inferencia INT8 con TFLite
- âœ… Umbrales optimizados (global + por clase)
- âœ… Soporte multi-threading
- âœ… Sin dependencias externas (solo TFLite)

## ğŸ“ˆ Optimizaciones

### Anti-Overfitting (CrÃ­tico para ~1000 imÃ¡genes)

- Transfer learning (pesos ImageNet)
- Freezeâ†’unfreeze progresivo
- Dropout en heads
- AdamW con weight decay
- EarlyStopping + ReduceLROnPlateau
- Data augmentation SOTA
- Teacher-student distillation
- MixUp (opcional)

### OptimizaciÃ³n de TamaÃ±o

- Quantization Aware Training (QAT)
- Full-integer INT8 quantization
- Modelo final: ~3-4 MB
- Inferencia: solo CPU

## ğŸ“¦ Formato de Dataset

```
dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”œâ”€â”€ img2.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ train.txt
â”œâ”€â”€ val.txt
â””â”€â”€ test.txt
```

Formato de archivos .txt:
```
imagen1.jpg,clase1|clase2|clase3
imagen2.jpg,clase2
imagen3.jpg,              # Sin etiquetas (vÃ¡lido)
```

## ğŸ“¤ Salidas del Entrenamiento

El sistema genera todos los archivos necesarios:

1. âœ… `model_qat_int8.tflite` - Modelo cuantizado INT8
2. âœ… `labels.txt` - Clases en orden alfabÃ©tico
3. âœ… `metrics.json` - MÃ©tricas completas (F1, precision, recall)
4. âœ… `threshold_recommendation.json` - Umbrales optimizados
5. âœ… `inference_config.json` - ConfiguraciÃ³n completa para mÃ³vil

## ğŸ”§ ConfiguraciÃ³n

Ver `trainer/training/configs/default.yaml`:

```yaml
seed: 1337
num_classes: 7

teacher:
  input_size: 300
  batch_size: 16
  epochs_head: 10
  epochs_finetune: 30
  lr_head: 1.0e-3
  lr_finetune: 1.0e-4
  dropout: 0.4

student:
  input_size: 240
  batch_size: 32
  epochs_head: 10
  epochs_finetune: 40
  dropout: 0.3

distillation:
  alpha: 0.7
  temperature: 2.0

qat:
  epochs: 10
  lr: 1.0e-5
```

## ğŸ“š DocumentaciÃ³n

### Entrenamiento
- [README Completo](trainer/training/README.md) - GuÃ­a tÃ©cnica detallada
- [Sistema Completo](trainer/SISTEMA_COMPLETO.md) - Resumen del sistema
- [Inicio RÃ¡pido](trainer/INICIO_RAPIDO.md) - Quick start en 5 minutos

### Mobile
- [Plugin README](mobile/image_recognition/README.md) - DocumentaciÃ³n del plugin
- [Requerimientos](mobile/requerimientos) - Especificaciones tÃ©cnicas

## â±ï¸ Tiempos de Entrenamiento

Dataset de ~1000 imÃ¡genes:

- **CPU**: 2-3 horas
- **GPU (V100)**: 30-40 minutos
- **GPU (T4)**: 1-1.5 horas

## ğŸ§ª Testing

```bash
# Test de preprocesamiento
cd trainer/training
python tests/test_letterbox.py

# Test del plugin mÃ³vil
cd mobile/image_recognition/example
flutter test
flutter run
```

## ğŸ“Š MÃ©tricas de Rendimiento

### Modelo
- TamaÃ±o: ~3-4 MB (INT8)
- PrecisiÃ³n: F1 macro ~0.85-0.90 (dataset tÃ­pico)
- Velocidad: ~50-100ms por imagen (mÃ³vil mid-range)

### Compatibilidad
- âœ… Android API 21+
- âœ… iOS 12+
- âœ… CPU-only (sin GPU requerida)

## ğŸ¤ Contribuir

Este es un proyecto de la organizaciÃ³n Percepthor para sistemas de reconocimiento de imÃ¡genes optimizados para mÃ³viles.

## ğŸ“„ Licencia

Ver archivo LICENSE

## ğŸ‘¨â€ğŸ’» Autor

**Felipe Lara**
- Email: felipe@lara.ac
- OrganizaciÃ³n: Percepthor

## ğŸ™ Agradecimientos

- TensorFlow & TFLite team
- EfficientNet authors
- Flutter team

---

**Percepthor** - Optimizando IA para el mundo mÃ³vil
